{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:167: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "BASE_DIR = ''\n",
    "\n",
    "MAX_SENTENCE_PER_SESSION = 1\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "PRELOAD = False\n",
    "\n",
    "REGRESSION = False\n",
    "\n",
    "SENTENCE_EMBEDDING_SIZE = None\n",
    "SESSION_EMBEDDING_SIZE = None\n",
    "\n",
    "from liwc_tagger import tag, get_features\n",
    "\n",
    "features, liwc = get_features('liwc_feature.json')\n",
    "\n",
    "\n",
    "def split_train_test_set(df):\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "langdetect_count = 0\n",
    "\n",
    "df_reviews = pd.read_csv('oneperline.csv')  # , encoding='utf-8')\n",
    "df_reviews['len'] = df_reviews.text.str.len()\n",
    "df_reviews['rating'] = df_reviews['rating'].round()\n",
    "\n",
    "df_reviews = df_reviews[df_reviews['len'].between(10, 4000)]\n",
    "df_reviews = df_reviews[df_reviews.rating!=3]\n",
    "df_reviews['rating'] = np.where(df_reviews.rating > 3, 1, 0)\n",
    "\n",
    "\n",
    "df_rev_balanced = df_reviews\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def truncate_or_pad(sentence, n):\n",
    "    sentence_seq = list(map(lambda x: x.strip(), sentence.split(\"\\n\")))\n",
    "    L = len(sentence_seq)\n",
    "    if L >= n:\n",
    "        return sentence_seq[:n]\n",
    "    else:\n",
    "        return [\"\"] * (n - L) + sentence_seq\n",
    "\n",
    "\n",
    "pad_sentence = df_rev_balanced.text.map(lambda x: truncate_or_pad(x, MAX_SENTENCE_PER_SESSION)).values\n",
    "\n",
    "counter = 0\n",
    "def sentence_embedding_func(last_str, str):\n",
    "    global counter\n",
    "    global SENTENCE_EMBEDDING_SIZE\n",
    "    words = len(str.split(\" \"))\n",
    "\n",
    "    if str.startswith(\"AAAAA\"):\n",
    "        embed_speaker = [0, 1]\n",
    "    elif str.startswith(\"UUUUU\"):\n",
    "        embed_speaker = [1, 0]\n",
    "    else:\n",
    "        embed_speaker = [0, 0]\n",
    "\n",
    "    if str.startswith(\"AAAAA\") or str.startswith(\"UUUUU\"):\n",
    "        str = str[8:]\n",
    "\n",
    "    embed_sentence_length = [min(len(str), 400), ]\n",
    "    embed_word_length = [min(len(str.strip().split(\" \")), 100), ]\n",
    "\n",
    "    pos_word = [\"love\", \"friend\"]\n",
    "    neg_word = [\"stupid\", \"idiot\", \"fuck\"]\n",
    "    pos = False\n",
    "    neg = False\n",
    "    for p in pos_word:\n",
    "        if p in str:\n",
    "            pos = True\n",
    "            break\n",
    "\n",
    "    for n in neg_word:\n",
    "        if n in str:\n",
    "            neg = True\n",
    "            break\n",
    "\n",
    "    embed_sentiment = [1 if pos else 0, 1 if neg else 0]\n",
    "\n",
    "    if len(last_str) == 0 or len(str) == 0:\n",
    "        embed_overlap = [0,\n",
    "                         0,\n",
    "                         0,\n",
    "                         0,\n",
    "                         0,\n",
    "                         0]\n",
    "        embed_uniq_rate = [0, 0]\n",
    "    else:\n",
    "        this_vocab = set(str.strip(\"\\n\").split(\" \"))\n",
    "        last_vocab = set(str.strip(\"\\n\").split(\" \"))\n",
    "        embed_overlap = [1,\n",
    "                         len(this_vocab),\n",
    "                         len(last_vocab),\n",
    "                         len(this_vocab | last_vocab),\n",
    "                         len(this_vocab & last_vocab),\n",
    "                         len(this_vocab | last_vocab) / len(this_vocab & last_vocab),\n",
    "                         ]\n",
    "\n",
    "        embed_uniq_rate = [1, len(this_vocab) / words]\n",
    "\n",
    "    if \"wh\" in str or \"how\" in str:\n",
    "        embed_question = [1]\n",
    "    else:\n",
    "        embed_question = [0]\n",
    "\n",
    "    ret = embed_speaker + embed_sentence_length + embed_word_length + embed_sentiment + embed_uniq_rate + embed_question + embed_overlap\n",
    "    SENTENCE_EMBEDDING_SIZE = len(ret)\n",
    "\n",
    "    liwc_tagged = tag(str, features, liwc)\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    return ret + liwc_tagged\n",
    "\n",
    "\n",
    "def session_embedding_func(str):\n",
    "    global SESSION_EMBEDDING_SIZE\n",
    "\n",
    "    words = len(str.replace(\"\\n\", \" \").split(\" \"))\n",
    "    turns = len(str.split(\"\\n\"))\n",
    "    embed_session_length = [min(len(str), 100), min(len(str), 1000), min(len(str), 5000)]\n",
    "    embed_session_words = [min(words, 100), min(words, 1000), min(words, 5000)]\n",
    "    embed_session_turns = [turns]\n",
    "    pos_word = [\"love\", \"friend\"]\n",
    "    neg_word = [\"stupid\", \"idiot\", \"fuck\"]\n",
    "    pos = False\n",
    "    neg = False\n",
    "    for p in pos_word:\n",
    "        if p in str:\n",
    "            pos = True\n",
    "            break\n",
    "\n",
    "    for n in neg_word:\n",
    "        if n in str:\n",
    "            neg = True\n",
    "            break\n",
    "\n",
    "    embed_sentiment = [1 if pos else 0, 1 if neg else 0]\n",
    "\n",
    "    embed_uniq_rate = [len(set(str.replace(\"\\n\", \" \").split(\" \"))) / words]\n",
    "\n",
    "    ret = embed_session_length + embed_session_words + embed_session_turns + embed_sentiment + embed_uniq_rate\n",
    "    SESSION_EMBEDDING_SIZE = len(ret)\n",
    "    return ret\n",
    "\n",
    "\n",
    "X_sentence_aux_embedding = np.array(\n",
    "    [[sentence_embedding_func(last_sentence, sentence) for last_sentence, sentence in\n",
    "      zip([\"\"] + session[:-1:], session[::])] for session in pad_sentence], dtype=\"float32\")\n",
    "\n",
    "X_sentence_aux_embedding /= np.max(X_sentence_aux_embedding, axis=(0, 1,))\n",
    "\n",
    "X_session_aux_embedding = np.array([session_embedding_func(session) for session in df_rev_balanced.text.values],\n",
    "                                   dtype=\"float32\")\n",
    "X_session_aux_embedding /= np.max(X_session_aux_embedding, axis=(0,))\n",
    "\n",
    "SIZE = X_sentence_aux_embedding.shape[0]\n",
    "X_sentence_aux_embedding = X_sentence_aux_embedding.reshape(SIZE, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sentence_aux_embedding = np.nan_to_num(X_sentence_aux_embedding, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pf = open(\"pickled.pk\",\"wb\")\n",
    "X = np.concatenate([X_sentence_aux_embedding, X_session_aux_embedding], axis=1)\n",
    "# X = X_session_aux_embedding\n",
    "Y = df_rev_balanced.rating.values.astype(int)\n",
    "\n",
    "pickle.dump(X, pf)\n",
    "pickle.dump(Y,pf)\n",
    "pf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.160956422731\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=VALIDATION_SPLIT,\n",
    "                                                    random_state=9)\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(cohen_kappa_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12157, 98)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.121584236172\n"
     ]
    }
   ],
   "source": [
    "X_train_small = X_train[:10000]\n",
    "y_train_small = y_train[:10000]\n",
    "logreg = svm.SVC(C=1e5)\n",
    "logreg.fit(X_train_small, y_train_small)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(cohen_kappa_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62250185048112505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12157, 480)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12157, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sessi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12157,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_rev_balanced.rating.values.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.156173868807\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[800  91]\n",
      " [351 109]]\n",
      "0.672834937084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67357512953367871"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[835, 385],\n",
       "       [ 56,  75]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12114980949107645"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
